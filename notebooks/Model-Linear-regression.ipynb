{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2f5107-d6a1-41c7-80fd-97419a3f8f96",
   "metadata": {},
   "source": [
    "Collecting data from Yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abd07dc-10a4-45f1-bc94-4fe211515632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined and saved to CSV in the desired format.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the list of tickers and the S&P 500 index\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "index_ticker = '^GSPC'  # S&P 500 index ticker\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-02'\n",
    "end_date = '2023-12-29'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the stock data\n",
    "all_stock_data = pd.DataFrame()\n",
    "\n",
    "# Fetch historical stock data\n",
    "for ticker in tickers:\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    stock_data['Ticker'] = ticker\n",
    "    stock_data['Date'] = stock_data.index\n",
    "    stock_data.reset_index(drop=True, inplace=True)\n",
    "    all_stock_data = pd.concat([all_stock_data, stock_data])\n",
    "\n",
    "# Fetch historical S&P 500 data\n",
    "index_data = yf.download(index_ticker, start=start_date, end=end_date)\n",
    "index_data['Date'] = index_data.index\n",
    "index_data.reset_index(drop=True, inplace=True)\n",
    "index_data.rename(columns={'Close': 'Index_Close'}, inplace=True)\n",
    "\n",
    "# Merge stock data with index data on Date\n",
    "merged_data = pd.merge(all_stock_data, index_data[['Date', 'Index_Close']], on='Date', how='inner')\n",
    "\n",
    "# Select relevant columns and arrange them\n",
    "final_data = merged_data[['Date', 'Ticker', 'Close', 'Index_Close']]\n",
    "\n",
    "# Save the final data to a CSV file\n",
    "final_data.to_csv('stock_with_index_data.csv', index=False)\n",
    "\n",
    "print(\"Data combined and saved to CSV in the desired format.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dceb19a-a155-4d74-abc0-04b9f864d184",
   "metadata": {},
   "source": [
    "### Checking the data for errors such as missing values, duplicate rows, and outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8391f0a-325e-4313-b45f-ecbd43c78ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Date           0\n",
      "Ticker         0\n",
      "Close          0\n",
      "Index_Close    0\n",
      "dtype: int64\n",
      "Number of duplicate rows:  0\n",
      "Outliers detected in the following columns:\n",
      " {'Close': 54, 'Index_Close': 0}\n",
      "Data types of each column:\n",
      " Date            object\n",
      "Ticker          object\n",
      "Close          float64\n",
      "Index_Close    float64\n",
      "dtype: object\n",
      "Cleaned dataset saved to: cleaned_stock_with_index_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'stock_with_index_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# 2. Check for duplicate rows\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", duplicate_rows)\n",
    "\n",
    "# 3. Check for outliers\n",
    "# Here, we use the IQR method to detect outliers in numeric columns\n",
    "def detect_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_indices = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))].index\n",
    "        outliers[col] = outlier_indices\n",
    "    return outliers\n",
    "\n",
    "outliers = detect_outliers(data)\n",
    "print(\"Outliers detected in the following columns:\\n\", {k: len(v) for k, v in outliers.items()})\n",
    "\n",
    "# 4. Check data types\n",
    "data_types = data.dtypes\n",
    "print(\"Data types of each column:\\n\", data_types)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = 'cleaned_stock_with_index_data.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved to:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858c3ab-42b1-4549-a06f-9dbe9beaa8f8",
   "metadata": {},
   "source": [
    "### Addressing outliers using the IQR (Interquartile Range) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acad2516-c586-4511-a73e-ee3c1053a89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected and removed:\n",
      "              Date Ticker       Close  Index_Close\n",
      "6456   2021-07-26   META  372.459991  4422.299805\n",
      "6476   2021-07-28   META  373.279999  4400.640137\n",
      "6696   2021-08-27   META  372.630005  4509.370117\n",
      "6706   2021-08-30   META  380.660004  4528.790039\n",
      "6716   2021-08-31   META  379.380005  4522.680176\n",
      "6726   2021-09-01   META  382.049988  4524.089844\n",
      "6736   2021-09-02   META  375.279999  4536.950195\n",
      "6746   2021-09-03   META  376.260010  4535.430176\n",
      "6756   2021-09-07   META  382.179993  4520.029785\n",
      "6766   2021-09-08   META  377.570007  4514.069824\n",
      "6776   2021-09-09   META  378.000000  4493.279785\n",
      "6786   2021-09-10   META  378.690002  4458.580078\n",
      "6796   2021-09-13   META  376.510010  4468.729980\n",
      "6806   2021-09-14   META  376.529999  4443.049805\n",
      "6816   2021-09-15   META  373.920013  4480.700195\n",
      "6826   2021-09-16   META  373.059998  4473.750000\n",
      "7139   2021-10-29   TSLA  371.333344  4605.379883\n",
      "7149   2021-11-01   TSLA  402.863342  4613.669922\n",
      "7159   2021-11-02   TSLA  390.666656  4630.649902\n",
      "7169   2021-11-03   TSLA  404.619995  4660.569824\n",
      "7179   2021-11-04   TSLA  409.970001  4680.060059\n",
      "7189   2021-11-05   TSLA  407.363342  4697.529785\n",
      "7199   2021-11-08   TSLA  387.646667  4701.700195\n",
      "7289   2021-11-19   TSLA  379.019989  4697.959961\n",
      "7299   2021-11-22   TSLA  385.623322  4682.939941\n",
      "7319   2021-11-24   TSLA  372.000000  4701.459961\n",
      "7339   2021-11-29   TSLA  378.996674  4655.270020\n",
      "7349   2021-11-30   TSLA  381.586670  4567.000000\n",
      "7579   2022-01-03   TSLA  399.926666  4796.560059\n",
      "7589   2022-01-04   TSLA  383.196655  4793.540039\n",
      "8209   2022-04-04   TSLA  381.816681  4582.640137\n",
      "12287  2023-11-16   MSFT  376.170013  4508.240234\n",
      "12307  2023-11-20   MSFT  377.440002  4547.379883\n",
      "12317  2023-11-21   MSFT  373.070007  4538.189941\n",
      "12327  2023-11-22   MSFT  377.850006  4556.620117\n",
      "12337  2023-11-24   MSFT  377.429993  4559.339844\n",
      "12347  2023-11-27   MSFT  378.609985  4550.430176\n",
      "12357  2023-11-28   MSFT  382.700012  4554.890137\n",
      "12367  2023-11-29   MSFT  378.850006  4550.580078\n",
      "12377  2023-11-30   MSFT  378.910004  4567.799805\n",
      "12387  2023-12-01   MSFT  374.510010  4594.629883\n",
      "12407  2023-12-05   MSFT  372.519989  4567.180176\n",
      "12427  2023-12-07   MSFT  370.950012  4585.589844\n",
      "12437  2023-12-08   MSFT  374.230011  4604.370117\n",
      "12447  2023-12-11   MSFT  371.299988  4622.439941\n",
      "12457  2023-12-12   MSFT  374.380005  4643.700195\n",
      "12467  2023-12-13   MSFT  374.369995  4707.089844\n",
      "12497  2023-12-18   MSFT  372.649994  4740.560059\n",
      "12507  2023-12-19   MSFT  373.260010  4768.370117\n",
      "12527  2023-12-21   MSFT  373.540009  4746.750000\n",
      "12537  2023-12-22   MSFT  374.579987  4754.629883\n",
      "12547  2023-12-26   MSFT  374.660004  4774.750000\n",
      "12557  2023-12-27   MSFT  374.070007  4781.580078\n",
      "12567  2023-12-28   MSFT  375.279999  4783.350098\n",
      "Cleaned dataset without outliers saved to: cleaned_stock_with_index_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('cleaned_stock_with_index_data.csv')\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data['Close'].quantile(0.25)\n",
    "Q3 = data['Close'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify and remove outliers\n",
    "outliers = data[(data['Close'] < lower_bound) | (data['Close'] > upper_bound)]\n",
    "print(\"Outliers detected and removed:\\n\", outliers)\n",
    "\n",
    "# Remove outliers\n",
    "data_cleaned = data[(data['Close'] >= lower_bound) & (data['Close'] <= upper_bound)]\n",
    "\n",
    "# Save the cleaned data without outliers\n",
    "data_cleaned.to_csv('cleaned_stock_with_index_data_no_outliers.csv', index=False)\n",
    "\n",
    "print(\"Cleaned dataset without outliers saved to: cleaned_stock_with_index_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c7c2b-7004-4224-b332-46fb35628553",
   "metadata": {},
   "source": [
    "#### Getting data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc0cb9c-7e64-40d6-95a8-1e6a56d1e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stock data with index saved to: new_stock_with_index_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "index_ticker = '^GSPC'  # S&P 500 Index\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-07-31'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the stock data\n",
    "all_stock_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and fetch the data\n",
    "for ticker in tickers:\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    stock_data['Ticker'] = ticker\n",
    "    stock_data.reset_index(inplace=True)\n",
    "    all_stock_data = pd.concat([all_stock_data, stock_data], axis=0)\n",
    "\n",
    "# Download the S&P 500 index data\n",
    "index_data = yf.download(index_ticker, start=start_date, end=end_date)\n",
    "index_data.reset_index(inplace=True)\n",
    "index_data.rename(columns={'Close': 'Index_Close'}, inplace=True)\n",
    "\n",
    "# Merge stock data with index data on Date\n",
    "merged_data = pd.merge(all_stock_data, index_data[['Date', 'Index_Close']], on='Date', how='inner')\n",
    "\n",
    "# Select relevant columns and arrange them\n",
    "final_data = merged_data[['Date', 'Ticker', 'Close', 'Index_Close']]\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data.to_csv('new_stock_with_index_data.csv', index=False)\n",
    "\n",
    "print(\"New stock data with index saved to: new_stock_with_index_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a90a7-52dd-4ed6-9c93-0b361a765e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
