{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f31cf7-1d74-499f-98f9-438e2c60186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview:\n",
      "       Ticker       AAPL       AMZN       BRK-B      GOOGL         JNJ  \\\n",
      "0        Date        NaN        NaN         NaN        NaN         NaN   \n",
      "1  2019-01-02  37.793777  76.956497  202.800003  52.673550  109.850533   \n",
      "2  2019-01-03  34.029243  75.014000  191.660004  51.214722  108.104958   \n",
      "3  2019-01-04  35.481930  78.769501  195.199997  53.841705  109.919334   \n",
      "4  2019-01-07  35.402943  81.475502  196.910004  53.734329  109.214211   \n",
      "\n",
      "         JPM        META       MSFT      NVDA  ...       AAPL.5       AMZN.5  \\\n",
      "0        NaN         NaN        NaN       NaN  ...          NaN          NaN   \n",
      "1  83.855164  135.401749  95.673470  3.378612  ...  148158800.0  159662000.0   \n",
      "2  82.663452  131.469833  92.153801  3.174486  ...  365248800.0  139512000.0   \n",
      "3  85.710884  137.667099  96.439835  3.377867  ...  234428400.0  183652000.0   \n",
      "4  85.770477  137.766891  96.562813  3.556694  ...  219111200.0  159864000.0   \n",
      "\n",
      "     BRK-B.5     GOOGL.5      JNJ.5       JPM.5      META.5      MSFT.5  \\\n",
      "0        NaN         NaN        NaN         NaN         NaN         NaN   \n",
      "1  4802100.0  31868000.0  7631700.0  15670900.0  28146200.0  35329300.0   \n",
      "2  8540600.0  41960000.0  8654500.0  16286400.0  22717900.0  42579100.0   \n",
      "3  6611200.0  46022000.0  8831700.0  16935200.0  29002100.0  44060600.0   \n",
      "4  5423000.0  47446000.0  8404700.0  15430700.0  20089300.0  35656100.0   \n",
      "\n",
      "        NVDA.5       TSLA.5  \n",
      "0          NaN          NaN  \n",
      "1  508752000.0  174879000.0  \n",
      "2  705552000.0  104478000.0  \n",
      "3  585620000.0  110911500.0  \n",
      "4  709160000.0  113268000.0  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "Data after Date conversion:\n",
      "  Ticker       AAPL       AMZN       BRK-B      GOOGL         JNJ        JPM  \\\n",
      "0    NaT        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "1    NaT  37.793777  76.956497  202.800003  52.673550  109.850533  83.855164   \n",
      "2    NaT  34.029243  75.014000  191.660004  51.214722  108.104958  82.663452   \n",
      "3    NaT  35.481930  78.769501  195.199997  53.841705  109.919334  85.710884   \n",
      "4    NaT  35.402943  81.475502  196.910004  53.734329  109.214211  85.770477   \n",
      "\n",
      "         META       MSFT      NVDA  ...       AAPL.5       AMZN.5    BRK-B.5  \\\n",
      "0         NaN        NaN       NaN  ...          NaN          NaN        NaN   \n",
      "1  135.401749  95.673470  3.378612  ...  148158800.0  159662000.0  4802100.0   \n",
      "2  131.469833  92.153801  3.174486  ...  365248800.0  139512000.0  8540600.0   \n",
      "3  137.667099  96.439835  3.377867  ...  234428400.0  183652000.0  6611200.0   \n",
      "4  137.766891  96.562813  3.556694  ...  219111200.0  159864000.0  5423000.0   \n",
      "\n",
      "      GOOGL.5      JNJ.5       JPM.5      META.5      MSFT.5       NVDA.5  \\\n",
      "0         NaN        NaN         NaN         NaN         NaN          NaN   \n",
      "1  31868000.0  7631700.0  15670900.0  28146200.0  35329300.0  508752000.0   \n",
      "2  41960000.0  8654500.0  16286400.0  22717900.0  42579100.0  705552000.0   \n",
      "3  46022000.0  8831700.0  16935200.0  29002100.0  44060600.0  585620000.0   \n",
      "4  47446000.0  8404700.0  15430700.0  20089300.0  35656100.0  709160000.0   \n",
      "\n",
      "        TSLA.5  \n",
      "0          NaN  \n",
      "1  174879000.0  \n",
      "2  104478000.0  \n",
      "3  110911500.0  \n",
      "4  113268000.0  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "Missing dates: 1259\n",
      "Data after dropping invalid dates:\n",
      "Empty DataFrame\n",
      "Columns: [Ticker, AAPL, AMZN, BRK-B, GOOGL, JNJ, JPM, META, MSFT, NVDA, TSLA, AAPL.1, AMZN.1, BRK-B.1, GOOGL.1, JNJ.1, JPM.1, META.1, MSFT.1, NVDA.1, TSLA.1, AAPL.2, AMZN.2, BRK-B.2, GOOGL.2, JNJ.2, JPM.2, META.2, MSFT.2, NVDA.2, TSLA.2, AAPL.3, AMZN.3, BRK-B.3, GOOGL.3, JNJ.3, JPM.3, META.3, MSFT.3, NVDA.3, TSLA.3, AAPL.4, AMZN.4, BRK-B.4, GOOGL.4, JNJ.4, JPM.4, META.4, MSFT.4, NVDA.4, TSLA.4, AAPL.5, AMZN.5, BRK-B.5, GOOGL.5, JNJ.5, JPM.5, META.5, MSFT.5, NVDA.5, TSLA.5]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 61 columns]\n",
      "Duplicate rows: 0\n",
      "Data types after cleaning:\n",
      "Ticker    datetime64[ns]\n",
      "AAPL             float64\n",
      "AMZN             float64\n",
      "BRK-B            float64\n",
      "GOOGL            float64\n",
      "               ...      \n",
      "JPM.5            float64\n",
      "META.5           float64\n",
      "MSFT.5           float64\n",
      "NVDA.5           float64\n",
      "TSLA.5           float64\n",
      "Length: 61, dtype: object\n",
      "Cleaned data saved to cleaned_stock_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file, skipping the first row and treating the first proper row as the header\n",
    "file_path = 'cleaned_stock_data.csv'\n",
    "data = pd.read_csv(file_path, skiprows=1)\n",
    "\n",
    "# Print the first few rows to verify correct loading\n",
    "print(\"Initial Data Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# The date column is the first column in the dataset\n",
    "date_column = data.columns[0]\n",
    "\n",
    "# Ensure the 'Date' column is in datetime format, using errors='coerce' to handle non-date values\n",
    "data[date_column] = pd.to_datetime(data[date_column], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Print the first few rows to check the 'Date' conversion\n",
    "print(\"Data after Date conversion:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values in the 'Date' column\n",
    "missing_dates = data[date_column].isnull().sum()\n",
    "print(f\"Missing dates: {missing_dates}\")\n",
    "\n",
    "# Drop rows with invalid dates if any\n",
    "data = data.dropna(subset=[date_column])\n",
    "\n",
    "# Print the first few rows after dropping invalid dates\n",
    "print(\"Data after dropping invalid dates:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = data.duplicated()\n",
    "print(f\"Duplicate rows: {duplicate_rows.sum()}\")\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Display data types to ensure consistency\n",
    "print(\"Data types after cleaning:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_file_path = 'cleaned_stock_data_cleaned.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd525092-02ad-4a3d-ad34-537ade566c5b",
   "metadata": {},
   "source": [
    "# Downloading the yfinance data in a clean format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5e0645-8349-46c8-a350-89262f726bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download and formatting complete.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of stock symbols\n",
    "stocks = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate through each stock and download the data\n",
    "for stock in stocks:\n",
    "    # Download historical data\n",
    "    stock_data = yf.download(stock, start=\"2019-01-01\", end=\"2023-12-31\")\n",
    "    \n",
    "    # Add a column for the stock name\n",
    "    stock_data['Stock'] = stock\n",
    "    \n",
    "    # Reset index to have 'Date' as a column\n",
    "    stock_data.reset_index(inplace=True)\n",
    "    \n",
    "    # Reorder columns\n",
    "    stock_data = stock_data[['Date', 'Stock', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    data_frames.append(stock_data)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "formatted_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Save the formatted data to a new CSV file\n",
    "formatted_data.to_csv('formatted_stock_data.csv', index=False)\n",
    "\n",
    "print(\"Data download and formatting complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b8fc0-9487-4ca8-bdc5-96f1b4dfa2c9",
   "metadata": {},
   "source": [
    "## Converting the Data from strings to number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce654629-f5ed-44f6-8786-76c437240ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to formatted_stock_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'formatted_stock_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the columns to the appropriate numeric types\n",
    "# Assuming the first two columns are 'Date' and 'Stock', and we don't need to convert them\n",
    "columns_to_convert = data.columns[2:]  # Skip 'Date' and 'Stock' columns\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "\n",
    "# Save the DataFrame back to a CSV file\n",
    "output_file_path = 'formatted_stock_data_cleaned.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data cleaned and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac7c12-06bd-4118-8c2a-7b0ac7112fab",
   "metadata": {},
   "source": [
    "## Calculating the RSI and MACD for the specified stocks within the given timeframe using the pandas_ta library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cabdd89-0e06-4c8a-955d-e4fbf7bf98f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_ta\n",
      "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
      "     ---------------------------------------- 0.0/115.1 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/115.1 kB ? eta -:--:--\n",
      "     ------------- ----------------------- 41.0/115.1 kB 393.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 115.1/115.1 kB 838.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from pandas_ta) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "Building wheels for collected packages: pandas_ta\n",
      "  Building wheel for pandas_ta (setup.py): started\n",
      "  Building wheel for pandas_ta (setup.py): finished with status 'done'\n",
      "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218928 sha256=e698f8e3ab177d56f16ebce23e5faeb48f0962c5ce6716df3c32851d9afb1812\n",
      "  Stored in directory: c:\\users\\aakas\\appdata\\local\\pip\\cache\\wheels\\7f\\33\\8b\\50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
      "Successfully built pandas_ta\n",
      "Installing collected packages: pandas_ta\n",
      "Successfully installed pandas_ta-0.3.14b0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddaf0a3d-f03f-42b2-920e-5dbcd529f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close  \\\n",
      "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.793781   \n",
      "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  34.029240   \n",
      "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.481926   \n",
      "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.402946   \n",
      "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.077839   \n",
      "\n",
      "      Volume  RSI          MACD    MACD_Signal      MACD_Hist Ticker  \n",
      "0  148158800  NaN  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   AAPL  \n",
      "1  365248800  NaN  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   AAPL  \n",
      "2  234428400  NaN  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   AAPL  \n",
      "3  219111200  NaN  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   AAPL  \n",
      "4  164101200  NaN  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-02'\n",
    "end_date = '2023-12-29'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and calculate indicators\n",
    "for ticker in tickers:\n",
    "    # Fetch historical stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate RSI and MACD\n",
    "    data['RSI'] = ta.rsi(data['Close'])\n",
    "    data['MACD'], data['MACD_Signal'], data['MACD_Hist'] = ta.macd(data['Close'])\n",
    "    \n",
    "    # Add a column for the ticker\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    # Reset index to have Date as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Append to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "all_data.to_csv('stock_data_with_indicators.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94207d07-68aa-46f5-b138-ae467e399a98",
   "metadata": {},
   "source": [
    "## Calculating RSI and MACD again, the last result did not worked well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f8c9d4-b187-41ad-9db4-bbad713e9087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close  \\\n",
      "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.793781   \n",
      "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  34.029240   \n",
      "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.481926   \n",
      "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.402946   \n",
      "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.077839   \n",
      "\n",
      "      Volume  RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9 Ticker  \n",
      "0  148158800  NaN           NaN            NaN            NaN   AAPL  \n",
      "1  365248800  NaN           NaN            NaN            NaN   AAPL  \n",
      "2  234428400  NaN           NaN            NaN            NaN   AAPL  \n",
      "3  219111200  NaN           NaN            NaN            NaN   AAPL  \n",
      "4  164101200  NaN           NaN            NaN            NaN   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-02'\n",
    "end_date = '2023-12-29'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and calculate indicators\n",
    "for ticker in tickers:\n",
    "    # Fetch historical stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate RSI and MACD\n",
    "    data['RSI'] = ta.rsi(data['Close'])\n",
    "    macd = ta.macd(data['Close'])\n",
    "    \n",
    "    # Add MACD, MACD_Signal, and MACD_Hist to the DataFrame\n",
    "    data = pd.concat([data, macd], axis=1)\n",
    "    \n",
    "    # Add a column for the ticker\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    # Reset index to have Date as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Append to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "all_data.to_csv('stock_data_with_indicators.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587eaa72-183e-49bd-aefa-bfab093c41dc",
   "metadata": {},
   "source": [
    "## Using Forward Fill to Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e66da3-db84-43dd-9e09-1c1affa9f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close  \\\n",
      "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.793781   \n",
      "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  34.029240   \n",
      "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.481926   \n",
      "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.402946   \n",
      "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.077839   \n",
      "\n",
      "      Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9 Ticker  \n",
      "0  148158800  48.544578      2.016478      -0.274112       1.742551   AAPL  \n",
      "1  365248800  48.544578      2.016478      -0.274112       1.742551   AAPL  \n",
      "2  234428400  48.544578      2.016478      -0.274112       1.742551   AAPL  \n",
      "3  219111200  48.544578      2.016478      -0.274112       1.742551   AAPL  \n",
      "4  164101200  48.544578      2.016478      -0.274112       1.742551   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-02'\n",
    "end_date = '2023-12-29'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and calculate indicators\n",
    "for ticker in tickers:\n",
    "    # Fetch historical stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate RSI and MACD\n",
    "    data['RSI'] = ta.rsi(data['Close'])\n",
    "    macd = ta.macd(data['Close'])\n",
    "    \n",
    "    # Add MACD, MACD_Signal, and MACD_Hist to the DataFrame\n",
    "    data = pd.concat([data, macd], axis=1)\n",
    "    \n",
    "    # Add a column for the ticker\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    # Forward fill and backward fill missing values\n",
    "    data.ffill(inplace=True)\n",
    "    data.bfill(inplace=True)\n",
    "    \n",
    "    # Reset index to have Date as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Append to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "all_data.to_csv('stock_data_with_indicators_filled.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f347f5-62ef-44cb-8203-78716907ea45",
   "metadata": {},
   "source": [
    "### Calculating the other two indicators, Bollinger Bands and Moving Average (MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdbbd3d-d807-41c5-9c4e-f48eed6af344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close  \\\n",
      "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.793781   \n",
      "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  34.029240   \n",
      "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.481926   \n",
      "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.402946   \n",
      "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.077839   \n",
      "\n",
      "      Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \\\n",
      "0  148158800  48.544578      2.016478      -0.274112       1.742551   \n",
      "1  365248800  48.544578      2.016478      -0.274112       1.742551   \n",
      "2  234428400  48.544578      2.016478      -0.274112       1.742551   \n",
      "3  219111200  48.544578      2.016478      -0.274112       1.742551   \n",
      "4  164101200  48.544578      2.016478      -0.274112       1.742551   \n",
      "\n",
      "   BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0         MA  \\\n",
      "0   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "1   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "2   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "3   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "4   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "\n",
      "  Ticker  \n",
      "0   AAPL  \n",
      "1   AAPL  \n",
      "2   AAPL  \n",
      "3   AAPL  \n",
      "4   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-02'\n",
    "end_date = '2023-12-29'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and calculate indicators\n",
    "for ticker in tickers:\n",
    "    # Fetch historical stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate RSI and MACD\n",
    "    data['RSI'] = ta.rsi(data['Close'])\n",
    "    macd = ta.macd(data['Close'])\n",
    "    \n",
    "    # Add MACD, MACD_Signal, and MACD_Hist to the DataFrame\n",
    "    data = pd.concat([data, macd], axis=1)\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    bollinger = ta.bbands(data['Close'], length=20, std=2)\n",
    "    \n",
    "    # Add Bollinger Bands to the DataFrame\n",
    "    data = pd.concat([data, bollinger], axis=1)\n",
    "    \n",
    "    # Calculate Moving Average\n",
    "    data['MA'] = ta.sma(data['Close'], length=20)\n",
    "    \n",
    "    # Add a column for the ticker\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    # Forward fill and backward fill missing values\n",
    "    data.ffill(inplace=True)\n",
    "    data.bfill(inplace=True)\n",
    "    \n",
    "    # Reset index to have Date as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Append to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "all_data.to_csv('stock_data_with_all_indicators.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fb759-642a-4705-a5e9-70a03f8f43ea",
   "metadata": {},
   "source": [
    "## Check for any data errors:\n",
    "\n",
    "- Check for missing values: Ensure there are no missing values in the dataset.\n",
    "- Check for duplicate rows: Ensure there are no duplicate rows in the dataset.\n",
    "- Check for outliers: Identify any extreme values that may not make sense.\n",
    "- Data types: Ensure all columns have the correct data types.\n",
    "- Here is the code to perform these checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b1a3f33-969d-44f3-bec4-d8db9f8b7c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ace\n",
      "  Downloading ace-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from ace) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\aakas\\anaconda3\\lib\\site-packages (from ace) (1.12.0)\n",
      "Downloading ace-0.3.3-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: ace\n",
      "Successfully installed ace-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2c8cad8-eeb5-43bd-b0df-74e518200916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Date             0\n",
      "Open             0\n",
      "High             0\n",
      "Low              0\n",
      "Close            0\n",
      "Adj Close        0\n",
      "Volume           0\n",
      "RSI              0\n",
      "MACD_12_26_9     0\n",
      "MACDh_12_26_9    0\n",
      "MACDs_12_26_9    0\n",
      "BBL_20_2.0       0\n",
      "BBM_20_2.0       0\n",
      "BBU_20_2.0       0\n",
      "BBB_20_2.0       0\n",
      "BBP_20_2.0       0\n",
      "MA               0\n",
      "Ticker           0\n",
      "dtype: int64\n",
      "Number of duplicate rows:  0\n",
      "Outliers detected in the following columns:\n",
      " {'Open': 57, 'High': 53, 'Low': 54, 'Close': 54, 'Adj Close': 31, 'Volume': 1467, 'RSI': 13, 'MACD_12_26_9': 1161, 'MACDh_12_26_9': 1370, 'MACDs_12_26_9': 1188, 'BBL_20_2.0': 51, 'BBM_20_2.0': 30, 'BBU_20_2.0': 68, 'BBB_20_2.0': 698, 'BBP_20_2.0': 0, 'MA': 30}\n",
      "Data types of each column:\n",
      " Date              object\n",
      "Open             float64\n",
      "High             float64\n",
      "Low              float64\n",
      "Close            float64\n",
      "Adj Close        float64\n",
      "Volume             int64\n",
      "RSI              float64\n",
      "MACD_12_26_9     float64\n",
      "MACDh_12_26_9    float64\n",
      "MACDs_12_26_9    float64\n",
      "BBL_20_2.0       float64\n",
      "BBM_20_2.0       float64\n",
      "BBU_20_2.0       float64\n",
      "BBB_20_2.0       float64\n",
      "BBP_20_2.0       float64\n",
      "MA               float64\n",
      "Ticker            object\n",
      "dtype: object\n",
      "First few rows of the cleaned dataset:\n",
      "          Date       Open       High        Low      Close  Adj Close  \\\n",
      "0  2019-01-02  38.722500  39.712502  38.557499  39.480000  37.793781   \n",
      "1  2019-01-03  35.994999  36.430000  35.500000  35.547501  34.029240   \n",
      "2  2019-01-04  36.132500  37.137501  35.950001  37.064999  35.481926   \n",
      "3  2019-01-07  37.174999  37.207500  36.474998  36.982498  35.402946   \n",
      "4  2019-01-08  37.389999  37.955002  37.130001  37.687500  36.077839   \n",
      "\n",
      "      Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \\\n",
      "0  148158800  48.544578      2.016478      -0.274112       1.742551   \n",
      "1  365248800  48.544578      2.016478      -0.274112       1.742551   \n",
      "2  234428400  48.544578      2.016478      -0.274112       1.742551   \n",
      "3  219111200  48.544578      2.016478      -0.274112       1.742551   \n",
      "4  164101200  48.544578      2.016478      -0.274112       1.742551   \n",
      "\n",
      "   BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0         MA  \\\n",
      "0   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "1   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "2   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "3   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "4   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
      "\n",
      "  Ticker  \n",
      "0   AAPL  \n",
      "1   AAPL  \n",
      "2   AAPL  \n",
      "3   AAPL  \n",
      "4   AAPL  \n",
      "Cleaned dataset saved to: cleaned_stock_data_with_indicators.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'stock_data_with_all_indicators.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# 2. Check for duplicate rows\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", duplicate_rows)\n",
    "\n",
    "# 3. Check for outliers\n",
    "# Here, we use the IQR method to detect outliers in numeric columns\n",
    "def detect_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_indices = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))].index\n",
    "        outliers[col] = outlier_indices\n",
    "    return outliers\n",
    "\n",
    "outliers = detect_outliers(data)\n",
    "print(\"Outliers detected in the following columns:\\n\", {k: len(v) for k, v in outliers.items()})\n",
    "\n",
    "# 4. Check data types\n",
    "data_types = data.dtypes\n",
    "print(\"Data types of each column:\\n\", data_types)\n",
    "\n",
    "# Optional: If there are any issues, you can handle them accordingly\n",
    "# For example, you can fill missing values or drop duplicates\n",
    "# data.fillna(method='ffill', inplace=True)\n",
    "# data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = 'cleaned_stock_data_with_indicators.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "# Since ace_tools is not available in your environment, we will use the standard display\n",
    "# or print function to show the dataframe's head\n",
    "\n",
    "print(\"First few rows of the cleaned dataset:\\n\", data.head())\n",
    "\n",
    "print(\"Cleaned dataset saved to:\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a111e-5b38-4293-9d24-012e72ccbc77",
   "metadata": {},
   "source": [
    "## Summary of Findings:\n",
    "- Missing Values: There are no missing values in the dataset.\n",
    "- Duplicate Rows: There are no duplicate rows in the dataset.\n",
    "- Outliers: Outliers have been detected in multiple columns.\n",
    "- Data Types: The data types of each column are as expected.\n",
    "## Handling Outliers\n",
    "\n",
    "- Handle Outliers: Using the IQR method to handle outliers.\n",
    "- Save the Cleaned Data: Save the cleaned dataset after handling outliers.\n",
    "- Proceed with Model Training: Use the cleaned dataset to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e251de55-861a-4055-98de-351e827efa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>BBL_20_2.0</th>\n",
       "      <th>BBM_20_2.0</th>\n",
       "      <th>BBU_20_2.0</th>\n",
       "      <th>BBB_20_2.0</th>\n",
       "      <th>BBP_20_2.0</th>\n",
       "      <th>MA</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>38.220001</td>\n",
       "      <td>38.424999</td>\n",
       "      <td>37.877499</td>\n",
       "      <td>38.072498</td>\n",
       "      <td>36.446396</td>\n",
       "      <td>108092800</td>\n",
       "      <td>48.544578</td>\n",
       "      <td>2.016478</td>\n",
       "      <td>-0.274112</td>\n",
       "      <td>1.742551</td>\n",
       "      <td>36.117574</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>40.658676</td>\n",
       "      <td>11.829444</td>\n",
       "      <td>1.143979</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>37.567501</td>\n",
       "      <td>38.347500</td>\n",
       "      <td>37.512501</td>\n",
       "      <td>38.267502</td>\n",
       "      <td>36.633068</td>\n",
       "      <td>114843600</td>\n",
       "      <td>48.544578</td>\n",
       "      <td>2.016478</td>\n",
       "      <td>-0.274112</td>\n",
       "      <td>1.742551</td>\n",
       "      <td>36.117574</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>40.658676</td>\n",
       "      <td>11.829444</td>\n",
       "      <td>1.143979</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>38.270000</td>\n",
       "      <td>38.970001</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>38.735001</td>\n",
       "      <td>37.080601</td>\n",
       "      <td>122278800</td>\n",
       "      <td>48.544578</td>\n",
       "      <td>2.016478</td>\n",
       "      <td>-0.274112</td>\n",
       "      <td>1.742551</td>\n",
       "      <td>36.117574</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>40.658676</td>\n",
       "      <td>11.829444</td>\n",
       "      <td>1.143979</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>38.549999</td>\n",
       "      <td>39.415001</td>\n",
       "      <td>38.314999</td>\n",
       "      <td>38.965000</td>\n",
       "      <td>37.300770</td>\n",
       "      <td>119284800</td>\n",
       "      <td>48.544578</td>\n",
       "      <td>2.016478</td>\n",
       "      <td>-0.274112</td>\n",
       "      <td>1.742551</td>\n",
       "      <td>36.117574</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>40.658676</td>\n",
       "      <td>11.829444</td>\n",
       "      <td>1.143979</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>39.102501</td>\n",
       "      <td>39.182499</td>\n",
       "      <td>38.154999</td>\n",
       "      <td>38.325001</td>\n",
       "      <td>36.688118</td>\n",
       "      <td>121576000</td>\n",
       "      <td>48.544578</td>\n",
       "      <td>2.016478</td>\n",
       "      <td>-0.274112</td>\n",
       "      <td>1.742551</td>\n",
       "      <td>36.117574</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>40.658676</td>\n",
       "      <td>11.829444</td>\n",
       "      <td>1.143979</td>\n",
       "      <td>38.388125</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "4   2019-01-11  38.220001  38.424999  37.877499  38.072498  36.446396   \n",
       "6   2019-01-15  37.567501  38.347500  37.512501  38.267502  36.633068   \n",
       "7   2019-01-16  38.270000  38.970001  38.250000  38.735001  37.080601   \n",
       "8   2019-01-17  38.549999  39.415001  38.314999  38.965000  37.300770   \n",
       "10  2019-01-22  39.102501  39.182499  38.154999  38.325001  36.688118   \n",
       "\n",
       "       Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \\\n",
       "4   108092800  48.544578      2.016478      -0.274112       1.742551   \n",
       "6   114843600  48.544578      2.016478      -0.274112       1.742551   \n",
       "7   122278800  48.544578      2.016478      -0.274112       1.742551   \n",
       "8   119284800  48.544578      2.016478      -0.274112       1.742551   \n",
       "10  121576000  48.544578      2.016478      -0.274112       1.742551   \n",
       "\n",
       "    BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0         MA  \\\n",
       "4    36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
       "6    36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
       "7    36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
       "8    36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
       "10   36.117574   38.388125   40.658676   11.829444    1.143979  38.388125   \n",
       "\n",
       "   Ticker  \n",
       "4    AAPL  \n",
       "6    AAPL  \n",
       "7    AAPL  \n",
       "8    AAPL  \n",
       "10   AAPL  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_stock_data_with_indicators.csv'  # Use the correct path to your CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to remove outliers using the IQR method\n",
    "def remove_outliers(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[~((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))]\n",
    "    return df\n",
    "\n",
    "# Remove outliers\n",
    "cleaned_data = remove_outliers(data)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = 'cleaned_stock_data_with_indicators.csv'\n",
    "cleaned_data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "cleaned_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ca975-c96c-4526-a9c5-f1d2cfd52ca6",
   "metadata": {},
   "source": [
    "### Fetching data for training the model for different timeframes:\n",
    "#### I am fetching it separately so I can include every symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71a58be6-33bc-4323-8b1a-b6c9a9e2598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date        Open        High         Low       Close   Adj Close  \\\n",
      "0 2024-01-02  187.149994  188.440002  183.889999  185.639999  185.152283   \n",
      "1 2024-01-03  184.220001  185.880005  183.429993  184.250000  183.765945   \n",
      "2 2024-01-04  182.149994  183.089996  180.880005  181.910004  181.432098   \n",
      "3 2024-01-05  181.990005  182.759995  180.169998  181.179993  180.703995   \n",
      "4 2024-01-08  182.089996  185.600006  181.500000  185.559998  185.072495   \n",
      "\n",
      "     Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \\\n",
      "0  82488700  74.450966      0.877487      -1.106851       0.142733   \n",
      "1  58414500  74.450966      0.877487      -1.106851       0.142733   \n",
      "2  71983600  74.450966      0.877487      -1.106851       0.142733   \n",
      "3  62303300  74.450966      0.877487      -1.106851       0.142733   \n",
      "4  59144500  74.450966      0.877487      -1.106851       0.142733   \n",
      "\n",
      "   BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0          MA  \\\n",
      "0  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "1  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "2  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "3  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "4  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "\n",
      "  Ticker  \n",
      "0   AAPL  \n",
      "1   AAPL  \n",
      "2   AAPL  \n",
      "3   AAPL  \n",
      "4   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['AAPL', 'AMZN', 'BRK-B', 'GOOGL', 'JNJ', 'JPM', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-07-31'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and calculate indicators\n",
    "for ticker in tickers:\n",
    "    # Fetch historical stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate RSI and MACD\n",
    "    data['RSI'] = ta.rsi(data['Close'])\n",
    "    macd = ta.macd(data['Close'])\n",
    "    \n",
    "    # Add MACD, MACD_Signal, and MACD_Hist to the DataFrame\n",
    "    data = pd.concat([data, macd], axis=1)\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    bollinger = ta.bbands(data['Close'], length=20, std=2)\n",
    "    \n",
    "    # Add Bollinger Bands to the DataFrame\n",
    "    data = pd.concat([data, bollinger], axis=1)\n",
    "    \n",
    "    # Calculate Moving Average\n",
    "    data['MA'] = ta.sma(data['Close'], length=20)\n",
    "    \n",
    "    # Add a column for the ticker\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    # Forward fill and backward fill missing values\n",
    "    data.ffill(inplace=True)\n",
    "    data.bfill(inplace=True)\n",
    "    \n",
    "    # Reset index to have Date as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Append to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "all_data.to_csv('new_stock_data_with_all_indicators.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e91a23-b671-43c2-9307-0d480c51b956",
   "metadata": {},
   "source": [
    "### Clean the New Data\n",
    "#### Ensuring the new data is in the same format as my existing training data and calculate the indicators (RSI, MACD, Bollinger Bands, Moving Averages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf18d6-6878-417b-85df-74ea03e3a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c168b5-a4b5-442b-a4ad-526da8f8fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "# Load the new data\n",
    "new_data = pd.read_csv('new_stock_data.csv')\n",
    "\n",
    "# Ensure 'Date' column is in datetime format\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "\n",
    "# Calculate RSI\n",
    "new_data['RSI'] = new_data.groupby('Ticker')['Close'].transform(lambda x: talib.RSI(x, timeperiod=14))\n",
    "\n",
    "# Calculate MACD\n",
    "new_data['MACD'], new_data['MACD_Signal'], new_data['MACD_Hist'] = new_data.groupby('Ticker')['Close'].apply(\n",
    "    lambda x: talib.MACD(x, fastperiod=12, slowperiod=26, signalperiod=9)).transform(list).unstack()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "new_data['BB_Upper'], new_data['BB_Middle'], new_data['BB_Lower'] = new_data.groupby('Ticker')['Close'].apply(\n",
    "    lambda x: talib.BBANDS(x, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)).transform(list).unstack()\n",
    "\n",
    "# Calculate Moving Averages\n",
    "new_data['MA'] = new_data.groupby('Ticker')['Close'].transform(lambda x: talib.SMA(x, timeperiod=20))\n",
    "\n",
    "# Fill missing values if any\n",
    "new_data.fillna(method='ffill', inplace=True)\n",
    "new_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Save the cleaned new data\n",
    "new_data.to_csv('cleaned_new_stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f3129-b266-40cf-af6b-f5635e384cf0",
   "metadata": {},
   "source": [
    "### Check and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5161afa-3793-45aa-bd00-21f197dc3d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Date             0\n",
      "Open             0\n",
      "High             0\n",
      "Low              0\n",
      "Close            0\n",
      "Adj Close        0\n",
      "Volume           0\n",
      "RSI              0\n",
      "MACD_12_26_9     0\n",
      "MACDh_12_26_9    0\n",
      "MACDs_12_26_9    0\n",
      "BBL_20_2.0       0\n",
      "BBM_20_2.0       0\n",
      "BBU_20_2.0       0\n",
      "BBB_20_2.0       0\n",
      "BBP_20_2.0       0\n",
      "MA               0\n",
      "Ticker           0\n",
      "dtype: int64\n",
      "Number of duplicate rows:  0\n",
      "Outliers detected in the following columns:\n",
      " {'Open': 0, 'High': 0, 'Low': 0, 'Close': 0, 'Adj Close': 0, 'Volume': 166, 'RSI': 18, 'MACD_12_26_9': 110, 'MACDh_12_26_9': 124, 'MACDs_12_26_9': 113, 'BBL_20_2.0': 0, 'BBM_20_2.0': 0, 'BBU_20_2.0': 0, 'BBB_20_2.0': 155, 'BBP_20_2.0': 0, 'MA': 0}\n",
      "Data types of each column:\n",
      " Date              object\n",
      "Open             float64\n",
      "High             float64\n",
      "Low              float64\n",
      "Close            float64\n",
      "Adj Close        float64\n",
      "Volume             int64\n",
      "RSI              float64\n",
      "MACD_12_26_9     float64\n",
      "MACDh_12_26_9    float64\n",
      "MACDs_12_26_9    float64\n",
      "BBL_20_2.0       float64\n",
      "BBM_20_2.0       float64\n",
      "BBU_20_2.0       float64\n",
      "BBB_20_2.0       float64\n",
      "BBP_20_2.0       float64\n",
      "MA               float64\n",
      "Ticker            object\n",
      "dtype: object\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2024-01-02  187.149994  188.440002  183.889999  185.639999  185.152283   \n",
      "1  2024-01-03  184.220001  185.880005  183.429993  184.250000  183.765945   \n",
      "2  2024-01-04  182.149994  183.089996  180.880005  181.910004  181.432098   \n",
      "3  2024-01-05  181.990005  182.759995  180.169998  181.179993  180.703995   \n",
      "4  2024-01-08  182.089996  185.600006  181.500000  185.559998  185.072495   \n",
      "\n",
      "     Volume        RSI  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \\\n",
      "0  82488700  74.450966      0.877487      -1.106851       0.142733   \n",
      "1  58414500  74.450966      0.877487      -1.106851       0.142733   \n",
      "2  71983600  74.450966      0.877487      -1.106851       0.142733   \n",
      "3  62303300  74.450966      0.877487      -1.106851       0.142733   \n",
      "4  59144500  74.450966      0.877487      -1.106851       0.142733   \n",
      "\n",
      "   BBL_20_2.0  BBM_20_2.0  BBU_20_2.0  BBB_20_2.0  BBP_20_2.0          MA  \\\n",
      "0  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "1  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "2  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "3  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "4  179.047189  187.890498  196.733808    9.413259    0.508452  187.890498   \n",
      "\n",
      "  Ticker  \n",
      "0   AAPL  \n",
      "1   AAPL  \n",
      "2   AAPL  \n",
      "3   AAPL  \n",
      "4   AAPL  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aakas\\AppData\\Local\\Temp\\ipykernel_25564\\1210164326.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\aakas\\AppData\\Local\\Temp\\ipykernel_25564\\1210164326.py:36: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'new_stock_data_with_all_indicators.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# 2. Check for duplicate rows\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", duplicate_rows)\n",
    "\n",
    "# 3. Check for outliers\n",
    "# Here, we use the IQR method to detect outliers in numeric columns\n",
    "def detect_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_indices = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))].index\n",
    "        outliers[col] = outlier_indices\n",
    "    return outliers\n",
    "\n",
    "outliers = detect_outliers(data)\n",
    "print(\"Outliers detected in the following columns:\\n\", {k: len(v) for k, v in outliers.items()})\n",
    "\n",
    "# 4. Check data types\n",
    "data_types = data.dtypes\n",
    "print(\"Data types of each column:\\n\", data_types)\n",
    "\n",
    "# Handling missing values (if any)\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Dropping duplicate rows (if any)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = 'cleaned_new_stock_data_with_indicators.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac52c3-c7b8-4812-a94f-65119ecde60a",
   "metadata": {},
   "source": [
    "The data is well-prepared with no missing values and only a few outliers. Now, I will train the model using AutoML with the cleaned and enriched dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80717b1f-6889-435b-ad5a-d0f6cbc0fa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
